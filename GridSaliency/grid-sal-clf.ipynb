{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(mask, color=(1,0,0), width=3):\n",
    "    mapimg = (mask == 0).astype(int)\n",
    "\n",
    "    ver_seg = np.where(mapimg[:,1:] != mapimg[:,:-1])\n",
    "    hor_seg = np.where(mapimg[1:,:] != mapimg[:-1,:])\n",
    "\n",
    "\n",
    "    l = []\n",
    "    for p in zip(*hor_seg):\n",
    "        l.append((p[1], p[0]+1))\n",
    "        l.append((p[1]+1, p[0]+1))\n",
    "        l.append((np.nan,np.nan))\n",
    "\n",
    "    # and the same for vertical segments\n",
    "    for p in zip(*ver_seg):\n",
    "        l.append((p[1]+1, p[0]))\n",
    "        l.append((p[1]+1, p[0]+1))\n",
    "        l.append((np.nan, np.nan))\n",
    "\n",
    "\n",
    "    segments = np.array(l)\n",
    "\n",
    "    x0=0\n",
    "    x1=224\n",
    "    y0=0\n",
    "    y1=224\n",
    "\n",
    "    segments[:,0] = x0 + (x1-x0) * segments[:,0] / mapimg.shape[1]\n",
    "    segments[:,1] = y0 + (y1-y0) * segments[:,1] / mapimg.shape[0]\n",
    "    \n",
    "    plt.plot(segments[:,0], segments[:,1], color=color, linewidth=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "def tv_norm(input, tv_beta):\n",
    "    img = input[0, 0, :]\n",
    "    row_grad = torch.mean(torch.abs((img[:-1 , :] - img[1 :, :])).pow(tv_beta))\n",
    "    col_grad = torch.mean(torch.abs((img[: , :-1] - img[: , 1 :])).pow(tv_beta))\n",
    "    return row_grad + col_grad\n",
    "\n",
    "def preprocess_image(img):\n",
    "    means=[0.485, 0.456, 0.406]\n",
    "    stds=[0.229, 0.224, 0.225]\n",
    "\n",
    "    preprocessed_img = img.copy()[: , :, ::-1]\n",
    "    for i in range(3):\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "    preprocessed_img = \\\n",
    "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "\n",
    "    if use_cuda:\n",
    "        preprocessed_img_tensor = torch.from_numpy(preprocessed_img).cuda()\n",
    "    else:\n",
    "        preprocessed_img_tensor = torch.from_numpy(preprocessed_img)\n",
    "\n",
    "    preprocessed_img_tensor.unsqueeze_(0)\n",
    "    return Variable(preprocessed_img_tensor, requires_grad = False)\n",
    "\n",
    "def sv_res(path, content, area_mask = None, do_mask = False):\n",
    "    plt.ioff()\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(np.uint8(255*content))\n",
    "    if do_mask: \n",
    "        draw_line(area_mask, width=4, color=(0,0,0.7))\n",
    "    fig.savefig(path, bbox_inches='tight')\n",
    "    \n",
    "def save(name, mask, img, blurred, area_mask = None, do_mask = False, full_mask = False):\n",
    "    mask = mask.cpu().data.numpy()[0]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "\n",
    "   # mask = (mask - np.min(mask)) / np.max(mask)\n",
    "    mask = 1 - mask\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n",
    "    \n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = 1.0*heatmap + np.float32(img)/255\n",
    "    cam = cam / np.max(cam)\n",
    "\n",
    "    img = np.float32(img) / 255\n",
    "    perturbated = np.multiply(1 - mask, img) + np.multiply(mask, blurred)    \n",
    "\n",
    "    pre_name = './results-clf/' + name + '/' + name\n",
    "    if do_mask:\n",
    "        pre_name = pre_name + '-mask'\n",
    "    if full_mask:\n",
    "        pre_name = pre_name + '-full'\n",
    "        \n",
    "    cv2.imwrite(pre_name +  \"-perturbated.png\", np.uint8(255*perturbated))\n",
    "    sv_res(pre_name + \"-heatmap.png\", heatmap, area_mask, do_mask)\n",
    "    cv2.imwrite(pre_name + \"-mask.png\", np.uint8(255*mask))\n",
    "    sv_res(pre_name + \"-cam.png\", cam, area_mask, do_mask)\n",
    "\n",
    "def numpy_to_torch(img, requires_grad = True):\n",
    "    if len(img.shape) < 3:\n",
    "        output = np.float32([img])\n",
    "    else:\n",
    "        output = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "    output = torch.from_numpy(output)\n",
    "    if use_cuda:\n",
    "        output = output.cuda()\n",
    "\n",
    "    output.unsqueeze_(0)\n",
    "    v = Variable(output, requires_grad = requires_grad)\n",
    "    return v\n",
    "\n",
    "def load_model():\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    #model = models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True, num_classes=21)    \n",
    "    model.eval()\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "    \n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_mask(do_mask = False, mask = \"dog\", full_mask = False):\n",
    "    if (not do_mask): return np.zeros((224, 224), dtype = np.float32)\n",
    "    if mask == \"dog\":\n",
    "        if not full_mask:\n",
    "            return np.load('./faces/dog-mask.npy')\n",
    "        return np.load('./full/dog-full.npy')\n",
    "    \n",
    "    if mask == \"cat\":\n",
    "        if not full_mask:\n",
    "            return np.load('./faces/cat-mask.npy')\n",
    "        return np.load('./full/cat-full.npy')\n",
    "    \n",
    "    if mask == \"person\":\n",
    "        if not full_mask:\n",
    "            return np.load('./faces/person-mask.npy')\n",
    "        return np.load('./full/person-full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_classification(name, do_mask = False, full_mask = False):\n",
    "    tv_beta = 3\n",
    "    learning_rate = 0.1\n",
    "    max_iterations = 500\n",
    "    l1_coeff = 0.01\n",
    "    tv_coeff = 0.2\n",
    "    image_path = \"./original-images/\" + name + \".png\"\n",
    "\n",
    "    model = load_model()\n",
    "    original_img = cv2.imread(image_path, 1)\n",
    "    original_img = cv2.resize(original_img, (224, 224))\n",
    "    img = np.float32(original_img) / 255\n",
    "\n",
    "    blurred_img_init = np.float32(cv2.medianBlur(original_img, 11))/255\n",
    "\n",
    "    # Convert to torch variables\n",
    "    img = preprocess_image(img)\n",
    "    blurred_img = preprocess_image(blurred_img_init)\n",
    "\n",
    "    mask_init = np.ones((28, 28), dtype = np.float32)\n",
    "    mask = numpy_to_torch(mask_init)\n",
    "\n",
    "    area_mask = get_area_mask(do_mask, name, full_mask)\n",
    "    mask_static = numpy_to_torch(area_mask, requires_grad = False)\n",
    "\n",
    "    upsample = torch.nn.UpsamplingBilinear2d(size=(224, 224)).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam([mask], lr=learning_rate)\n",
    "\n",
    "    target = torch.nn.Softmax()(model(img))\n",
    "    category = np.argmax(target.cpu().data.numpy())\n",
    "    print(\"-------------------\")\n",
    "    print(\"IMAGE:\" + name)\n",
    "    print(\"-------------------\")\n",
    "    print(\"Category with highest probability\")\n",
    "    print(category)\n",
    "    print(\"Optimizing.. \")\n",
    "    print(\"Iterations:\")\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        if i%100 == 0: \n",
    "            print(i)\n",
    "\n",
    "        def_mask = torch.mul((1-mask_static), upsample(mask))\n",
    "\n",
    "        upsampled_mask = def_mask\n",
    "        upsampled_mask = upsampled_mask.expand(1, 3, upsampled_mask.size(2),  upsampled_mask.size(3))\n",
    "        \n",
    "        # Use the mask to perturbated the input image.\n",
    "        perturbated_input = img.mul(upsampled_mask) + blurred_img.mul(1-upsampled_mask)\n",
    "        \n",
    "           \n",
    "        outputs = torch.nn.Softmax()(model(perturbated_input))\n",
    "        \n",
    "        loss = (\n",
    "            l1_coeff*torch.mean(torch.abs(1 - def_mask)) + \n",
    "            ((outputs[0, category] - target[0, category])/ \n",
    "             torch.mean(torch.abs(1 - mask_static)))\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        mask.data.clamp_(0, 1)\n",
    "\n",
    "    upsampled_mask = upsample(def_mask)\n",
    "    save(name, upsampled_mask, original_img, blurred_img_init, area_mask, do_mask, full_mask)\n",
    "     \n",
    "    print(\"--------------END--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "IMAGE:dog\n",
      "-------------------\n",
      "Category with highest probability\n",
      "245\n",
      "Optimizing.. \n",
      "Iterations:\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "--------------END--------------\n",
      "-------------------\n",
      "IMAGE:dog\n",
      "-------------------\n",
      "Category with highest probability\n",
      "245\n",
      "Optimizing.. \n",
      "Iterations:\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "--------------END--------------\n",
      "-------------------\n",
      "IMAGE:dog\n",
      "-------------------\n",
      "Category with highest probability\n",
      "245\n",
      "Optimizing.. \n",
      "Iterations:\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "--------------END--------------\n",
      "-------------------\n",
      "IMAGE:person\n",
      "-------------------\n",
      "Category with highest probability\n",
      "902\n",
      "Optimizing.. \n",
      "Iterations:\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "--------------END--------------\n",
      "-------------------\n",
      "IMAGE:person\n",
      "-------------------\n",
      "Category with highest probability\n",
      "902\n",
      "Optimizing.. \n",
      "Iterations:\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------END--------------\n",
      "-------------------\n",
      "IMAGE:person\n",
      "-------------------\n",
      "Category with highest probability\n",
      "902\n",
      "Optimizing.. \n",
      "Iterations:\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "--------------END--------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "img_names = [\"dog\", \"person\"]\n",
    "for name in img_names:\n",
    "    try:\n",
    "        os.mkdir(\"results-clf/\" + name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    explain_classification(name, do_mask = True, full_mask = True)\n",
    "    explain_classification(name, do_mask = True)    \n",
    "    explain_classification(name, do_mask = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
